{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#Exercise 4 - mushroom dataset\n",
    "df = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "#1 = edable, 0=poisonous\n",
    "y2 = df['class']\n",
    "X2 = df.drop(['class'], axis=1)\n",
    "\n",
    "X_all = pd.concat((X2, y2.T), axis=1)\n",
    "X_all = clean_data(X_all)\n",
    "\n",
    "X_train, X_test, X_prun = separate_data(X_all)\n",
    "\n",
    "y_train = X_train.iloc[:,-1]\n",
    "X_train = X_train.iloc[:,:-1]\n",
    "\n",
    "root = learn(X_train, y_train, impurity_measure='entropy', feature_names=True)\n",
    "\n",
    "#If you want to run it with pruning\n",
    "#root = learn(X_train, y_train, impurity_measure='entropy', pruning=X_prun, feature_names=False)\n",
    "\n",
    "#Small dataset I used to build up the application, don't think this will work now because of the multiple labels\n",
    "training_data = np.array([\n",
    "    ['Green', 3, 'sweet', 'Apple'],\n",
    "    ['Yellow', 3, 'sour','Apple'],\n",
    "    ['Red', 1, 'sweet', 'Grape'],\n",
    "    ['Red', 1, 'sweet', 'Grape'],\n",
    "    ['Yellow', 3, 'sour', 'Lemon'],\n",
    "    ['Green', 2, 'sour', 'Lime'],\n",
    "    ['Green', 1, 'sweet', 'Grape'],\n",
    "    ['Red', 5, 'sweet', 'Melon'],\n",
    "    ['Yellow', 5, 'sweet', 'Melon'],\n",
    "])\n",
    "\n",
    "\n",
    "#Here the user needs to import a dataset, put all the data into X, and all the targets into y\n",
    "X = training_data[:, :(len(training_data[0])-1)]\n",
    "y = np.array([training_data[:, 3]])\n",
    "\n",
    "#To build the tree run this line\n",
    "#root = learn(X, y, impurity_measure=?, pruning=?, feature_names=?)\n",
    "#Example of predict\n",
    "#label predict(['Purple', 5, 'salty'], root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def separate_data(data, test_share=0.3, pruning_share=0.1):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: separate_data\n",
    "\n",
    "    Separates the whole dataset into training, test and pruning set\n",
    "\n",
    "    :param data: the whole dataset\n",
    "    :type data: pandas dataframe\n",
    "\n",
    "    :param test_share: the size of the testset in percentage - default = 0.3\n",
    "    :type test_share: float\n",
    "\n",
    "    :param pruning_share: the size of the pruningset in percentage - default = 0.1\n",
    "    :type pruning_share: float\n",
    "\n",
    "    :return training_data: trainingset filled with data\n",
    "    :type training_data: pandas dataframe\n",
    "\n",
    "    :return test_data: testset filled with data\n",
    "    :type test_data: pandas dataframe\n",
    "\n",
    "    :return prun_data: trainingset filled with data\n",
    "    :type prun_data: pandas dataframe\n",
    "    \"\"\"\n",
    "    num_prun = int(len(data)*pruning_share)\n",
    "    num_test = int(len(data)*test_share)\n",
    "    \n",
    "    test_data = data.iloc[:num_test,:]\n",
    "    prun_data = data.iloc[num_test:(num_prun+num_test), :]\n",
    "    training_data = data.iloc[(num_test+num_prun):, :]\n",
    "\n",
    "    return training_data, test_data, prun_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Tree(object):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: Tree\n",
    "\n",
    "    At tree class I got from the second answer:\n",
    "    https://stackoverflow.com/questions/41760856/most-simple-tree-data-structure-in-python-that-can-be-easily-traversed-in-both\n",
    "\n",
    "    I have done som adjustments, and added a couple of variables\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: 2D array\n",
    "\n",
    "    :param split_value: where to split the data in current node(Tree) - deafault = None\n",
    "    :type split_value: string or number(float, int)\n",
    "\n",
    "    :param col: the column in the data that is used to split - default = None\n",
    "    :type col: int\n",
    "\n",
    "    :param children: holds the children with a key that is True or False based on the value comparison with the split_value,\n",
    "    answer to the question. And value is the children node - default = None\n",
    "    :type children: dict\n",
    "\n",
    "    :param parent: parent to the current node - default = None\n",
    "    :type parent: Tree\n",
    "    \"\"\" \n",
    "    def __init__(self, data, split_value=None, col=None, children=None, parent=None):\n",
    "        self.data = data\n",
    "        self.split_value = split_value\n",
    "        self.col = col\n",
    "        self.children = children or {}\n",
    "        self.parent = parent\n",
    "\n",
    "    def add_child(self, data, key):\n",
    "        new_child = Tree(data, parent=self)\n",
    "        self.children.update({key: new_child})\n",
    "        return new_child\n",
    "\n",
    "    def is_root(self):\n",
    "        return self.parent is None\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return not self.children\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.is_leaf():\n",
    "            return str(self.data)\n",
    "        return '{data} [{children}]'.format(data=self.data, children=', '.join(map(str, self.children)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: clean_data\n",
    "\n",
    "    Removes rows with '?' value in it\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: pandas dataframe\n",
    "\n",
    "    :return: data, without the rows with '?' in it\n",
    "    :return type: pandas dataframe\n",
    "    \"\"\"\n",
    "    return data[~(data == '?').any(axis=1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_number(value):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: is_number\n",
    "\n",
    "    Validate if \"value\" is a number or not\n",
    "\n",
    "    :param value:  validation value\n",
    "    :type value: string or int\n",
    "\n",
    "    :return: if value is number or not\n",
    "    :return type: bool\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def value_count(data, col):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: value_count\n",
    "\n",
    "    Counts the different values in a category\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: 2D array\n",
    "\n",
    "    :param col: the column in the data that are supposed to be counted\n",
    "    :type col: int\n",
    "\n",
    "    :return: a collection where key is the category value and value is the number of times the key has occurred\n",
    "    :return type: dict\n",
    "    \"\"\"\n",
    "    count = {}\n",
    "    for row in data:\n",
    "        label = row[col]\n",
    "        if label not in count:\n",
    "            count[label] = 0\n",
    "        count[label] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_label(data):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: get_label\n",
    "\n",
    "    Gets the most common label in a dataset\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: 2D array\n",
    "\n",
    "    :return: the label thet occurred the most times\n",
    "    :return type: depends on label type, number(int, float) or string\n",
    "    \"\"\"\n",
    "    label_max = 0\n",
    "    label = None\n",
    "    count = value_count(data, -1)\n",
    "    \n",
    "    for key, value in count.items():\n",
    "        if(value > label_max):\n",
    "            label = key\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy(data):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: entropy\n",
    "\n",
    "    Finds the entropy of a dataset\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: 2D array\n",
    "\n",
    "    :return: the entropy\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    label_col = -1\n",
    "    count = value_count(data, label_col)\n",
    "    entropy = 0\n",
    "    #Calculation of entropy\n",
    "    for key, value in count.items():\n",
    "        entropy = entropy - (((value/len(data))*(math.log2(value/len(data)))))\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gini_index(data):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: gini_index\n",
    "\n",
    "    Finds the gini index of a dataset\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: 2D array\n",
    "\n",
    "    :return: the gini index\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    label_col = -1\n",
    "    count = value_count(data, label_col)\n",
    "    gini_index = 0\n",
    "    #Calculation of gini index\n",
    "    for key, value in count.items():\n",
    "        gini_index += (value/len(data))*(1-(value/len(data)))\n",
    "    return gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def question(split_value, new_value):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: question\n",
    "\n",
    "    Takes in two values and compare them\n",
    "\n",
    "    :param split_value: is the value that decides where to split the parentnode\n",
    "    :type split_value: string or number(float, int)\n",
    "\n",
    "    :param new_value: decides which child to put the row in after comparing it to split_value\n",
    "    :type new_value: string or number(float, int)\n",
    "\n",
    "    :return: the answer to the question\n",
    "    :return type: bool\n",
    "    \"\"\"\n",
    "    if is_number(split_value):\n",
    "        return int(new_value) >= int(split_value) \n",
    "    else:\n",
    "        return split_value == new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split(data, split_value, split_col):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: split\n",
    "\n",
    "    Splits a dataset into two parts, based on the split_value\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: 2D array\n",
    "\n",
    "    :param split_value: is the value that decides where to split the data\n",
    "    :type split_value: string or number(float, int)\n",
    "\n",
    "    :param split_col: the column where the split is happening\n",
    "    :type split_col: int\n",
    "\n",
    "    :return left_values: the \"False\" values, after comparing with split_value. Left children\n",
    "    :return type: 2D array\n",
    "\n",
    "    :return right_values: the \"True\" values, after comparing with split_value. Right children\n",
    "    :return type: 2D array\n",
    "    \"\"\"\n",
    "    left_values, right_values = [],[]\n",
    "    \n",
    "    for row in data:    \n",
    "        if question(split_value, row[split_col]):\n",
    "            right_values = np.append(right_values, row)\n",
    "        else:\n",
    "            left_values = np.append(left_values, row)\n",
    "    \n",
    "    #To get it correctly formatted in a 2D np.array, I couldn't find a betterway\n",
    "    left_values = np.reshape(left_values, (-1, len(data[0])))\n",
    "    right_values = np.reshape(right_values, (-1, len(data[0])))\n",
    "    \n",
    "    \n",
    "    return left_values, right_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_info_gain_entropy(data):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: best_info_gain_entropy\n",
    "\n",
    "    Finds the smallest summarzed entropi in the children after a split. Same as highest information gain\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: 2D array\n",
    "\n",
    "    :return split_value: the value to split on from the best information gain\n",
    "    :type split_value: string or number(float, int)\n",
    "\n",
    "    :param min_col: the column where the best split_value is\n",
    "    :type min_col: int\n",
    "\n",
    "    :return left_values: the \"False\" values, after comparing with split_value. Left children\n",
    "    :return type: 2D array\n",
    "\n",
    "    :return right_values: the \"True\" values, after comparing with split_value. Right children\n",
    "    :return type: 2D array\n",
    "    \"\"\"\n",
    "    entropy_parent = entropy(data)\n",
    "    min_entropy=entropy_parent\n",
    "    min_col=0\n",
    "    split_value = None\n",
    "    min_left_child=[]\n",
    "    min_right_child=[]\n",
    "    \n",
    "    #loops through the columns\n",
    "    for i in range(len(data[0])-1):\n",
    "        unique_values = np.unique(data[:, i])\n",
    "        #loops through the unique values in a column \n",
    "        for value in unique_values:\n",
    "            #do a split on every value\n",
    "            left_child, right_child = split(data, value, i)\n",
    "            #calculate the entropy\n",
    "            entropy_child = (len(left_child)/len(data))*entropy(left_child) + (len(right_child)/len(data))*entropy(right_child)\n",
    "            \n",
    "            if entropy_child < min_entropy:\n",
    "                min_entropy = entropy_child\n",
    "                min_col = i\n",
    "                split_value = value\n",
    "                min_left_child = left_child\n",
    "                min_right_child = right_child\n",
    "    \n",
    "    #Under is the IG, but we don't need it, because it's enough to find the smallest entropy in the children.\n",
    "    #After this we dosen't need the entropy or the IG anymore because we have the best split_value\n",
    "    \n",
    "    #information_gain = entropy_parent - min_entropy\n",
    "    \n",
    "    return split_value, min_col, min_left_child, min_right_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_info_gain_gi(data):\n",
    "    \"\"\"\n",
    "\n",
    "    gi_parent = gini_index(data)\n",
    "    min_gi=gi_parent\n",
    "    min_col=0    Doc.\n",
    "\n",
    "    Title: best_info\n",
    "\n",
    "    Finds the smallest summarzed gini index in the children after a split. Same as highest information gain\n",
    "\n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: 2D array\n",
    "\n",
    "    :return split_value: the value to split on from the best information gain\n",
    "    :type split_value: string or number(float, int)\n",
    "\n",
    "    :param min_col: the column where the best split_value is\n",
    "    :type min_col: int\n",
    "\n",
    "    :return left_values: the \"False\" values, after comparing with split_value. Left children\n",
    "    :return type: 2D array\n",
    "\n",
    "    :return right_values: the \"True\" values, after comparing with split_value. Right children\n",
    "    :return type: 2D array\n",
    "    \"\"\"\n",
    "    gi_parent = gini_index(data)\n",
    "    split_value = None\n",
    "    min_col=0\n",
    "    min_left_child = []\n",
    "    min_right_child = []\n",
    "    min_gi=gi_parent\n",
    "    #loops through the columns\n",
    "    for i in range(len(data[0])-1):\n",
    "        unique_values = np.unique(data[:, i])\n",
    "        #loops through the unique values in a column \n",
    "        for value in unique_values:\n",
    "            #do a split on every value\n",
    "            left_child, right_child = split(data, value, i)\n",
    "            #calculate the gini index\n",
    "            gi_child = (len(left_child)/len(data))*gini_index(left_child) + (len(right_child)/len(data))*gini_index(right_child)\n",
    "            \n",
    "            if gi_child < min_gi:\n",
    "                min_gi = gi_child\n",
    "                min_col = i\n",
    "                split_value = value\n",
    "                min_left_child = left_child\n",
    "                min_right_child = right_child            \n",
    "    #Under is the IG, but we don't need it, because it's enough to find the smallest gini index in the child.\n",
    "    #After this we dosen't need the gini index or the IG anymore because enough to have the best split_value\n",
    "    \n",
    "    #information_gain = gi_parent - min_gi      \n",
    "    \n",
    "    return split_value, min_col, min_left_child, min_right_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(parent_node, impurity_measure):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: build_tree\n",
    "\n",
    "    Recursive function for building the tree\n",
    "\n",
    "    :param parent_node: the current node in the tree\n",
    "    :type parent_node: Tree\n",
    "\n",
    "    :param impurity_measure: defines which impurity measure to use. Entorpy or gini index\n",
    "    :type impurity_measure: string\n",
    "\n",
    "    :return: no return, the tree makes itself when running this function\n",
    "    \"\"\"\n",
    "    if(impurity_measure == 'entropy'):\n",
    "        split_value, col, left_child, right_child = best_info_gain_entropy(parent_node.data)\n",
    "    elif(impurity_measure == 'gini'):\n",
    "        split_value, col, left_child, right_child = best_info_gain_gi(parent_node.data)\n",
    "    else:\n",
    "        print(\"Not valid impurity measure\")\n",
    "        return\n",
    "        \n",
    "    parent_node.split_value = split_value\n",
    "    parent_node.col = col\n",
    "    \n",
    "    #If split_value == None - is the node a leaf\n",
    "    if (parent_node.split_value == None):\n",
    "        return\n",
    "    \n",
    "    #builds down to the left first\n",
    "    left_node = parent_node.add_child(left_child, key='False')  \n",
    "    build_tree(left_node, impurity_measure)\n",
    "    \n",
    "    #then go to the right\n",
    "    right_node = parent_node.add_child(right_child, key='True')\n",
    "    build_tree(right_node, impurity_measure)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numbers(data): \n",
    "    \"\"\"\n",
    "    Doc.\n",
    "    \n",
    "    Title: convert_to_numbers\n",
    "    \n",
    "    :param data: is a collection of data and the labels(target), seperated in categories\n",
    "    :type data: pandas dataframe\n",
    "    \n",
    "    :return: data translated to numbers\n",
    "    :return type: 2D array\n",
    "    \"\"\"\n",
    "    for column in data.columns: \n",
    "        data[column] = pd.factorize(data[column])[0]\n",
    "    data = data.values #numpy array \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn(X, y, impurity_measure='entropy', pruning=None, feature_names=False):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: learn\n",
    "\n",
    "    This function learns a decision tree classifier from X and y\n",
    "\n",
    "    :param X: all data in a dataset\n",
    "    :type X: 2D array\n",
    "\n",
    "    :param y: all the labels in a dataset\n",
    "    :type y: 2D array\n",
    "\n",
    "    :param impurity_measure: defines which impurity measure to use. Entorpy or gini index\n",
    "    :type impurity_measure: string\n",
    "\n",
    "    :param pruning: a set of data used to pruning - default = Node\n",
    "    :type pruning: pandas dataframe\n",
    "\n",
    "    :param feature_names: choose to show tree with feauters or not\n",
    "    :type feature_names: bool\n",
    "\n",
    "    :return root: returns the root of the tree\n",
    "    :return type: Tree\n",
    "    \"\"\"\n",
    "    \n",
    "    X_all = pd.concat((X, y.T), axis=1)\n",
    "    X_all = convert_to_numbers(X_all)\n",
    "    \n",
    "    \n",
    "    root = Tree(X_all)\n",
    "    build_tree(root, impurity_measure)\n",
    "    \n",
    "    \n",
    "    if pruning is not None:\n",
    "        prun = convert_to_numbers(X_prun)\n",
    "        do_pruning(root, root, prun)\n",
    "        \n",
    "    if feature_names:\n",
    "        print_tree(root)\n",
    "    \n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (x, tree):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "\n",
    "    Title: predict\n",
    "\n",
    "    Predict the label(target) of a set of data\n",
    "\n",
    "    :param x: the set of data you are supposed to predict\n",
    "    :type x: array\n",
    "\n",
    "    :param tree: the trained decision tree you use to get the prediction\n",
    "    :type tree: Tree\n",
    "\n",
    "    :return: the predicted laple\n",
    "    :return type: depends on label type, number(int, float) or string\n",
    "    \"\"\"\n",
    "    node = tree\n",
    "    leaf = False\n",
    "    \n",
    "    #As long as node isn't a leaf, go to the correct children\n",
    "    while not leaf:\n",
    "        if is_number(x[node.col]):\n",
    "            node = node.children[str(int(x[node.col])>=int(node.split_value))]\n",
    "        else:\n",
    "            node = node.children[str(x[node.col]== node.split_value)]\n",
    "        leaf = node.is_leaf()\n",
    "    label=get_label(node.data)\n",
    "    return (label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(data, root):\n",
    "    \"\"\"\n",
    "    Doc.\n",
    "    \n",
    "    Title: errer_rate\n",
    "    \n",
    "    Runs a test dataset through the tree and returns number of mistaken predictions\n",
    "    \n",
    "    :param data: a testing dataset\n",
    "    :type data: 2D array\n",
    "    \n",
    "    :param root: the tree you run the testdata on\n",
    "    :type root: Tree\n",
    "    \n",
    "    :return: the total error after predicting the whole dataset\n",
    "    :return type: int\n",
    "    \"\"\"\n",
    "    \n",
    "    error_total = 0\n",
    "    for row in data:\n",
    "        pred_label = predict(row, root)\n",
    "        \n",
    "        if pred_label != float(row[-1]):\n",
    "            error_total += 1\n",
    "\n",
    "    return error_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pruning(temp_root, node, X_pruning): \n",
    "    \"\"\"\n",
    "    Doc.\n",
    "    \n",
    "    Title: do_pruning\n",
    "    \n",
    "    A recursive function that can help to avoid overfitting\n",
    "    \n",
    "    :param temp_root: holds the root element(node) the whole time\n",
    "    :type temp_root: Tree\n",
    "    \n",
    "    :param node: current node , used to check if any leafs should be deleted\n",
    "    :type node: Tree\n",
    "\n",
    "    :param X_pruning: the dataset used to predict and find the error rate\n",
    "    :type X_pruning: 2D array\n",
    "    \n",
    "    :return: no return param here, the pruning will happen when running the function \n",
    "    \"\"\"\n",
    "    \n",
    "    if not node.is_leaf():\n",
    "        do_pruning(temp_root, node.children['False'], X_pruning)\n",
    "        do_pruning(temp_root, node.children['True'], X_pruning)\n",
    "    else:\n",
    "        return\n",
    "    #if both children is leaf\n",
    "    if node.children['False'].is_leaf() and node.children['True'].is_leaf():\n",
    "        children_temp = node.children\n",
    "        prev_error = error_rate(X_pruning, temp_root)\n",
    "        node.children = None\n",
    "        new_error = error_rate(X_pruning, temp_root)\n",
    "        if(new_error<=prev_error):\n",
    "            return\n",
    "        else:\n",
    "            node.children=children_temp\n",
    "            return\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node):\n",
    "    \"\"\"\n",
    "    Doc. \n",
    "    \n",
    "    Title: print_tree\n",
    "    \n",
    "    Prints out the steps in the tree (recommend to look at this step by step and paint it)\n",
    "\n",
    "    :param node: the current node\n",
    "    :type node: Tree\n",
    "\n",
    "    :return: no return value\n",
    "    \"\"\"\n",
    "    print (node.data)\n",
    "    if node.is_leaf():\n",
    "        print ('Leaf ↑')\n",
    "        print ('Label: ' + str(get_label(node.data)))\n",
    "        print ('')\n",
    "    else:\n",
    "        if is_number(node.split_value):\n",
    "            print ('Split value: >='+str(node.split_value)+ \" in col: \" + str(node.col))\n",
    "        else:\n",
    "            print ('Split value: =='+node.split_value)\n",
    "    print ('')      \n",
    "    if not node.is_leaf():\n",
    "        print('Left child (False)   ↙')\n",
    "        print_tree(node.children['False'])\n",
    "        print('↘  Rightchild (True)')\n",
    "        print_tree(node.children['True'])\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = learn(X_train, y_train)\n",
    "X_performance = convert_to_numbers(X_test)\n",
    "error_performance= error_rate(X_performance, root)\n",
    "print ('Number of errors with: impurity_measure=entropy, pruning=None: ' + str(error_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = learn(X_train, y_train, impurity_measure='gini')\n",
    "error_performance= error_rate(X_performance, root)\n",
    "print ('Number of errors with: impurity_measure=gini index, pruning=None: ' + str(error_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = learn(X_train, y_train, pruning=X_prun)\n",
    "error_performance= error_rate(X_performance, root)\n",
    "print ('Number of errors with: impurity_measure=entropy, pruning=Yes: ' + str(error_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = learn(X_train, y_train, impurity_measure='gini', pruning=X_prun)\n",
    "error_performance= error_rate(X_performance, root)\n",
    "print ('Number of errors with: impurity_measure=gini index, pruning=Yes: ' + str(error_performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = learn(X_train, y_train, pruning=X_prun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_test = convert_to_numbers(X_test)\n",
    "error_test= error_rate(test_X_test, root)\n",
    "print (\"Accuracy with test data, with my test: \" + str(100-(100*(error_test/len(X_test)))) + \"%\")\n",
    "\n",
    "test_X_prun = convert_to_numbers(X_prun)\n",
    "error_prun = error_rate(test_X_prun, root)\n",
    "print (\"Accuracy with pruning data, with my test: \" + str(100-(100*(error_prun/len(X_prun))))+ \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier('entropy')\n",
    "sk_X_train = pd.concat((X_train, y_train.T), axis=1)\n",
    "sk_X_train = convert_to_numbers(sk_X_train)\n",
    "sk_y_train = sk_X_train[:,-1]\n",
    "sk_X_train =sk_X_train[:,:-1]\n",
    "\n",
    "\n",
    "clf.fit(sk_X_train, sk_y_train)\n",
    "\n",
    "y_sk_test = X_test.iloc[:,-1]\n",
    "X_sk_test = X_test.iloc[:,:-1]\n",
    "y_sk_test = y_sk_test.values\n",
    "X_sk_test = X_sk_test.values\n",
    "\n",
    "\n",
    "score_test= clf.score(X=X_sk_test, y=y_sk_test)\n",
    "\n",
    "\n",
    "X_sk_prun = convert_to_numbers(X_prun)\n",
    "y_sk_prun = X_sk_prun[:,-1]\n",
    "X_sk_prun = X_sk_prun[:,:-1]\n",
    "\n",
    "print(\"Accuracy with test data, with sklearn: \" + str(100*score_test))\n",
    "\n",
    "score_prun = clf.score(X=X_sk_prun, y=y_sk_prun)\n",
    "print(\"Accuracy with pruning data, with sklearn: \" + str(100*score_prun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
